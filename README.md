# ğŸŒ¾ AgroPulse: Wheat Disease Detection Model

AgroPulse is an ğŸŒ± agricultural prediction system designed to detect wheat leaf diseases and provide crop health insights using machine learning. Built with ğŸš€ **FastAPI**,** ğŸ§  TensorFlow**, and powered by **â˜ï¸ AWS Services** (EC2 and S3), this project aims to assist farmers and agricultural enthusiasts worldwide.


## Key Features:
**âœ¨ Disease Prediction:** Detects wheat leaf diseases using advanced deep learning models.

**âš¡ FastAPI Backend:** A modern, high-performance web framework.

**â˜ï¸ AWS S3 Integration:** Efficient model and data storage in the cloud.

**ğŸ³ Dockerized Deployment:** Fully containerized for seamless deployment.

**ğŸ“Š Data Pipelines:** Robust pipelines for preprocessing and training.

---

## ğŸ› ï¸ Key Contributors

ğŸ‘¨â€ğŸ’» **[Kishor Patil](https://github.com/kishorpatil)** 

ğŸ‘©â€ğŸ’» **[Pradnyanad Bhadarge](https://github.com/pradnyanand09)** 

ğŸ‘¨â€ğŸ’» **[Shreejit Bhakte](https://github.com/shreejitbhakte)**

ğŸ‘¨â€ğŸ’» **[Yuvraj Sankilwar](https://github.com/yuvrajofficials)**


---

## ğŸ“‘ Table of Contents
1. ğŸ—‚ï¸ Project Structure
2. ğŸš€ Installation
3. ğŸ–¥ï¸ Usage
4. ğŸ”— API Endpoints
5. â˜ï¸ Model and Data Storage
6. ğŸ³ Docker Setup
7. ğŸ“œ License


---

## Project Structure

The project follows a standard directory structure for FastAPI-based applications, organized as follows:


```plaintext
ğŸ“‚ agro-pulse-backend/
â”œâ”€â”€ ğŸ“ config/                    # YAML configuration files
â”‚   â”œâ”€â”€ ğŸ“ dev.yaml               # Development configuration
â”‚   â””â”€â”€ ğŸ“ prod.yaml              # Production configuration
â”œâ”€â”€ ğŸ“ data/                      # Data storage
â”‚   â”œâ”€â”€ ğŸ“‚ raw/                   # Raw data
â”‚   â”œâ”€â”€ ğŸ“‚ processed/             # Processed data
â”‚   â””â”€â”€ ğŸ“‚ interim/               # Interim data
â”œâ”€â”€ ğŸ“ docs/                      # Documentation
â”‚   â””â”€â”€ ğŸ“ README.md              # Project-specific documentation
â”œâ”€â”€ ğŸ“ logs/                      # Log files
â”œâ”€â”€ ğŸ“ models/                    # Machine learning models
â”‚   â”œâ”€â”€ ğŸ“‚ checkpoints/           # Intermediate model checkpoints
â”‚   â””â”€â”€ ğŸ“‚ final/                 # Final saved models
â”œâ”€â”€ ğŸ“ notebooks/                 # Jupyter notebooks for experimentation
â”œâ”€â”€ ğŸ“ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ ğŸ“ download_data.py       # Script to download datasets
â”‚   â””â”€â”€ ğŸ“ train_model.py         # Script to train ML models
â”œâ”€â”€ ğŸ“ src/                       # Core source code
â”‚   â”œâ”€â”€ ğŸ“‚ api/                   # API routing
â”‚   â”‚   â”œâ”€â”€ ğŸ“ routes.py          # API endpoints
â”‚   â”‚   â””â”€â”€ ğŸ“ app.py             # FastAPI app setup
â”‚   â”œâ”€â”€ ğŸ“‚ configs/               # Configuration logic
â”‚   â”‚   â”œâ”€â”€ ğŸ“ base.py            # Base configuration setup
â”‚   â”‚   â””â”€â”€ ğŸ“ custom.py          # Custom configuration overrides
â”‚   â”œâ”€â”€ ğŸ“‚ pipelines/             # Data and training pipelines
â”‚   â”‚   â”œâ”€â”€ ğŸ“ data_pipeline.py   # Data preprocessing pipeline
â”‚   â”‚   â””â”€â”€ ğŸ“ train_pipeline.py  # Model training pipeline
â”‚   â”œâ”€â”€ ğŸ“‚ tasks/                 # Task implementations
â”‚   â”‚   â”œâ”€â”€ ğŸ“ model_training.py  # Model training tasks
â”‚   â”‚   â””â”€â”€ ğŸ“ monitoring.py      # Monitoring and validation tasks
â”‚   â”œâ”€â”€ ğŸ“‚ tests/                 # Unit tests
â”‚   â”‚   â”œâ”€â”€ ğŸ“ test_api.py        # Tests for API functionality
â”‚   â”‚   â””â”€â”€ ğŸ“ test_pipeline.py   # Tests for pipelines
â”‚   â”œâ”€â”€ ğŸ“‚ utils/                 # Utility modules
â”‚   â”‚   â”œâ”€â”€ ğŸ“ logger.py          # Custom logger utility
â”‚   â”‚   â””â”€â”€ ğŸ“ file_handler.py    # File handling utilities
â”‚   â””â”€â”€ ğŸ“‚ workers/               # Background tasks and workers
â”‚       â””â”€â”€ ğŸ“ task_runner.py     # Task runner implementation
â”œâ”€â”€ âš™ï¸ .env                       # Environment variables
â”œâ”€â”€ âš™ï¸ .gitignore                 # Git ignore file
â”œâ”€â”€ ğŸ³ Dockerfile                 # Dockerfile for containerization
â”œâ”€â”€ âš™ï¸ Makefile                   # Makefile for automating tasks
â”œâ”€â”€ âš™ï¸ pyproject.toml             # Python project configuration
â”œâ”€â”€ âš™ï¸ requirements.txt           # Python dependencies
â””â”€â”€ ğŸ“œ README.md                  # Main project documentation

```




## ğŸš€ Installation

### âœ…  Prerequisites

Before you begin, ensure you have the following installed on your system:

- **ğŸPython 3.9+**
- **ğŸ“¦Pip**: Python package installer
- **ğŸ³Docker** (Optional but recommended for containerization)
- **â˜ï¸AWS CLI** (For working with AWS S3 and EC2)

### ğŸ› ï¸ Steps to Install:

1.Clone the repository:
   ```bash
   git clone https://github.com/yuvrajofficials/agro-pulse-backend.git
   cd agro-pulse-backend
   ```

2.Create a Python Virtual Environment:
 ```bash 
 python3 -m venv venv
source venv/bin/activate
```


3.Install dependencies:
```bash
pip install -r requirements.txt
```

4.Configure AWS (if working with S3/EC2): 

Make sure you have the AWS CLI installed and configured with the necessary credentials:

```bash
aws configure
```



## ğŸ–¥ï¸ Usage
### ğŸƒRunning Locally
- Start the FastAPI app locally:

```bash
uvicorn app.main:app --reload
```

- Open your browser and navigate to:
 ```bash 
 ğŸŒhttp://127.0.0.1:8000 
 ```


### ğŸ“–Interacting with the API

Once the server is running, you can use Swagger UI for interactive API documentation. Visit the following URL:

```bash
ğŸŒ http://127.0.0.1:8000/docs
```
Here, you can test various endpoints like disease prediction by uploading an image.


## ğŸŒ API Endpoints
**ğŸ§ª Disease Prediction**

- Endpoint: `/predict-disease/`

- Method: `POST`

- Description:  Upload an image of a wheat leaf to get disease predictions.
- ğŸ“©Request Body:
```bash
Content-Type: multipart/form-data
File: Image of the wheat leaf.
```

- ğŸ“‹Example Request:

```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/predict-disease/' \
  -H 'accept: application/json' \
  -F 'file=@/path/to/leaf_image.jpg'
```
- ğŸ“¤Response:
```bash
{
  "disease": "Wheat Yellow Rust",
  "confidence": 0.87
}
```

## ğŸ“‚Model and Data Storage

The trained model and dataset are stored in AWS S3 for scalable access and management.

###ğŸš€ Uploading Files to S3
Use the AWS CLI to upload models and datasets to your S3 bucket:

ğŸ—‚ï¸ **Upload Model:**
```bash
aws s3 cp /path/to/your/model.h5 s3://agro-pulse/models/
```

ğŸ“Š **Upload Dataset:**
```bash
aws s3 cp /path/to/your/dataset.csv s3://agro-pulse/datasets/
```

Once uploaded, the backend fetches the model and data directly from S3 at runtime, ensuring seamless scalability.

## ğŸ³ Docker Setup
This project is containerized using Docker, making it easy to deploy anywhere.

ğŸ“¦ **1. Building the Docker Image**
Navigate to the project directory and build the Docker image:

```bash
docker build -t agropulse-backend .
```
â–¶ï¸ **2. Running the Docker Container**
Run the Docker container to start the application:

```bash
docker run -d -p 8000:8000 agropulse-backend
```
The FastAPI app will be available at: ğŸŒ http://localhost:8000

## ğŸ“œ License

This project is licensed under the `Apache 2.0 License` - see the [LICENSE](https://github.com/yuvrajofficials/agro-pulse-backend/blob/main/LICENSE) file for details.

## ğŸ™Œ Acknowledgements
**ğŸï¸FastAPI:** Fast and high-performance web framework for building APIs with Python 3.8+.

**ğŸ¤–TensorFlow:** Open-source machine learning library used for training and inference of the model.

**â˜ï¸AWS S3:** Cloud storage service used for storing the models and datasets.

**ğŸ³Docker:** Used for creating a containerized environment for the project.
